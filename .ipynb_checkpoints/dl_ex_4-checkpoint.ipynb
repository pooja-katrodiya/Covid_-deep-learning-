{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal: Build a model that can identify the brand from the product image uploaded.\n",
    "\n",
    "### Data Info:\n",
    "\n",
    "- Data has not been collected well and has a lot of gaps.\n",
    "- Product images without brand info should be considered as fake images.\n",
    "- Ignore the brand info with no product images.\n",
    "\n",
    "\n",
    "### Model Info:\n",
    "\n",
    "Build a stacked model system with two CNN models.\n",
    "\n",
    "First model: \n",
    "- Identifies if a product image belongs to the original brand or a fake brand.\n",
    "- Cannot use any additional features beside the image.\n",
    "\n",
    "Second model:\n",
    "- Looks at the product images identified as genuine and then determines which brand it belongs to.\n",
    "- Can use some additional features that are reliable to improve its prediction accuracy.\n",
    "\n",
    "\n",
    "To impress management:\n",
    "- Build interpretability into your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization, Dropout \n",
    "from keras.utils import load_img, img_to_array, np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15137 entries, 0 to 15136\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    15137 non-null  int64  \n",
      " 1   ID            15137 non-null  int64  \n",
      " 2   GenderType    15137 non-null  object \n",
      " 3   Type          15137 non-null  object \n",
      " 4   SubType       15137 non-null  object \n",
      " 5   Article       15137 non-null  object \n",
      " 6   PrimaryColor  15131 non-null  object \n",
      " 7   Seasonal      15136 non-null  object \n",
      " 8   Year          15136 non-null  float64\n",
      " 9   Use           15133 non-null  object \n",
      " 10  Brand         15137 non-null  object \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('branddataset/brand_info.csv')\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Peter England', 'Titan', 'Puma', 'Fila', 'Gini and Jony',\n",
       "       'Baggit', 'Adidas', 'John', 'Scullers', 'Nike', 'Arrow',\n",
       "       'Wrangler', 'Lotto', 'United Colors of Benetton', 'Fastrack',\n",
       "       'Jockey', 'Ray Ban', 'Chromozome', 'Spykar', 'Lee', 'Elle',\n",
       "       'Casio'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Brand'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create numpy array of all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"branddataset/images/\"\n",
    "images_list = os.listdir(image_dir)\n",
    "\n",
    "no_of_images = len(images_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 53, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_img(image_dir + images_list[4327])\n",
    "img_arr = img_to_array(img).astype(int)\n",
    "\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = []\n",
    "target = []\n",
    "\n",
    "\n",
    "for i in images_list:\n",
    "    img = load_img(image_dir + i)\n",
    "    img_arr = img_to_array(img).astype(int)\n",
    "    shape = img_arr.shape\n",
    "\n",
    "    if (shape[0] != 80) or (shape[1] != 60):\n",
    "        continue \n",
    "\n",
    "    img_data.append(img_arr)\n",
    "\n",
    "    # originial - 1, fake - 0\n",
    "    if int(i.rstrip('.jpg')) in data['ID']:\n",
    "        target.append(1)\n",
    "    else:\n",
    "        target.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44303, 80, 60, 3)\n",
      "(44303,)\n"
     ]
    }
   ],
   "source": [
    "# converting lists to numoy array\n",
    "\n",
    "X = np.array(img_data)\n",
    "Y = np.array(target)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22151, 80, 60, 3)\n",
      "(22152, 80, 60, 3)\n",
      "(22151,)\n",
      "(22152,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35442, 2)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Y_train = np_utils.to_categorical(y_train)\n",
    "#Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "#Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build CNN model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=(80,60,3)))\n",
    "\n",
    "model.add(Conv2D(64,\n",
    "                 kernel_size=(3,3),\n",
    "                 strides=(1,1),\n",
    "                 padding='same',\n",
    "                 activation='relu'\n",
    "                 ))\n",
    "\n",
    "model.add(Conv2D(128,\n",
    "                 kernel_size=(3,3),\n",
    "                 strides=(1,1),\n",
    "                 padding='same',\n",
    "                 activation='relu'\n",
    "                 ))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256,\n",
    "                 kernel_size=(3,3),\n",
    "                 strides=(2,2),\n",
    "                 padding='same',\n",
    "                 activation='relu'\n",
    "                 ))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer='adam'\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "87/87 [==============================] - 203s 2s/step - loss: 0.4830 - accuracy: 0.8072 - val_loss: 3.7386 - val_accuracy: 0.5936\n",
      "Epoch 2/10\n",
      "87/87 [==============================] - 183s 2s/step - loss: 0.3352 - accuracy: 0.8570 - val_loss: 1.2402 - val_accuracy: 0.5109\n",
      "Epoch 3/10\n",
      "87/87 [==============================] - 176s 2s/step - loss: 0.2838 - accuracy: 0.8805 - val_loss: 1.8783 - val_accuracy: 0.4019\n",
      "Epoch 4/10\n",
      "87/87 [==============================] - 177s 2s/step - loss: 0.2441 - accuracy: 0.8963 - val_loss: 0.3928 - val_accuracy: 0.8358\n",
      "Epoch 5/10\n",
      "87/87 [==============================] - 177s 2s/step - loss: 0.1993 - accuracy: 0.9200 - val_loss: 0.4267 - val_accuracy: 0.8427\n",
      "Epoch 6/10\n",
      "87/87 [==============================] - 178s 2s/step - loss: 0.1713 - accuracy: 0.9315 - val_loss: 1.0831 - val_accuracy: 0.6622\n",
      "Epoch 7/10\n",
      "87/87 [==============================] - 177s 2s/step - loss: 0.1281 - accuracy: 0.9515 - val_loss: 3.9535 - val_accuracy: 0.3688\n",
      "Epoch 8/10\n",
      "87/87 [==============================] - 178s 2s/step - loss: 0.1086 - accuracy: 0.9591 - val_loss: 0.3746 - val_accuracy: 0.8625\n",
      "Epoch 9/10\n",
      "87/87 [==============================] - 179s 2s/step - loss: 0.0771 - accuracy: 0.9710 - val_loss: 0.5533 - val_accuracy: 0.8056\n",
      "Epoch 10/10\n",
      "87/87 [==============================] - 176s 2s/step - loss: 0.0580 - accuracy: 0.9788 - val_loss: 0.4117 - val_accuracy: 0.8608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28fdf4d90>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=256, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build CNN Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
